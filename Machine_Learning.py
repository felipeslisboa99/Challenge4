import streamlit as st
import pandas as pd
import xgboost as xgb
from prophet import Prophet
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

# T√≠tulo da p√°gina
def app():
    st.title("ü§ñ Modelo de Machine Learning")

    # Carregar os dados
    @st.cache_data
    def load_data():
        return pd.read_excel("base_petroleo.xlsx")

    df = load_data()

    # Exibir os dados carregados
    st.write("### Dados Carregados")
    st.dataframe(df.head())

    # Convers√£o de Data para DateTime
    if 'data' in df.columns:
        df['data'] = pd.to_datetime(df['data'])
        df = df.drop(columns=['data'])  # Remover a coluna de data

    # Garantir que h√° colunas dispon√≠veis
    if df.empty or len(df.columns) < 2:
        st.error("‚ö† Erro: N√£o h√° colunas suficientes para modelagem!")
        return

    # Selecionar automaticamente a vari√°vel alvo (√∫ltima coluna)
    variaveis = df.columns.tolist()
    target = variaveis[-1]  # √öltima coluna √© a vari√°vel alvo
    features = variaveis[:-1]  # Todas as outras s√£o preditoras

    # **Transformar valores categ√≥ricos em num√©ricos**
    df = pd.get_dummies(df, drop_first=True)

    # **Remover NaN**
    df = df.dropna()

    # Definir X e y
    X = df[features]
    y = df[target]

    # **Garantir que h√° dados v√°lidos**
    if X.empty or y.empty:
        st.error("‚ö† Erro: N√£o h√° dados suficientes para treinar o modelo!")
        return

    st.write(f"üîπ Tamanho de X: {X.shape}, Tamanho de y: {y.shape}")

    # **Divis√£o treino e teste**
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # **Treinamento do modelo XGBoost**
    try:
        model_xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
        model_xgb.fit(X_train, y_train)
        pred_xgb = model_xgb.predict(X_test)
    except Exception as e:
        st.error(f"‚ö† Erro no treinamento do XGBoost: {e}")
        return

    # **Treinamento do modelo Random Forest**
    model_rf = RandomForestRegressor(n_estimators=100, random_state=42)
    model_rf.fit(X_train, y_train)
    pred_rf = model_rf.predict(X_test)

    # **Fun√ß√£o para calcular m√©tricas**
    def calcular_metricas(y_true, y_pred):
        return {
            "MAE": mean_absolute_error(y_true, y_pred),
            "MSE": mean_squared_error(y_true, y_pred),
            "R¬≤": r2_score(y_true, y_pred)
        }

    # **Exibir m√©tricas**
    st.write("### üéØ Desempenho dos Modelos")
    st.write("**XGBoost:**", calcular_metricas(y_test, pred_xgb))
    st.write("**Random Forest:**", calcular_metricas(y_test, pred_rf))

    # **Previs√£o com Prophet**
    st.write("### üîÆ Previs√£o com Prophet")
    df_prophet = df[[target]].reset_index().rename(columns={'index': 'ds', target: 'y'})
    model_prophet = Prophet()
    model_prophet.fit(df_prophet)

    future = model_prophet.make_future_dataframe(periods=30)
    forecast = model_prophet.predict(future)

    st.write("### üîç Previs√£o para os pr√≥ximos 30 dias")
    st.dataframe(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(30))
